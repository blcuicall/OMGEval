# OMGEvalğŸ˜®: An Open Multilingual Generative Evaluation Benchmark for Foundation Models
<div align="center"><img src="./figures/omgeval_logo.png" width="450px"></div>

## èƒŒæ™¯

è¿‘ä¸€å¹´ï¼Œå¤§æ¨¡å‹å‘å±•è¿…é€Ÿï¼Œå¸¦åŠ¨äº†â¼€ç³»åˆ—é€šç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è¿…é€Ÿå‘å±•ï¼Œå¯¹å¤§æ¨¡å‹æ€§èƒ½çš„è¯„æµ‹éšä¹‹æ¶Œç°ã€‚

ä»è¯„æµ‹èƒ½åŠ›ä¸Šæ¥çœ‹ï¼Œç”±äºç›®å‰çš„è¯„æµ‹æ•°æ®é›†ä¸»è¦æ˜¯åˆ©ç”¨äººç±»è¯•é¢˜åŠå…¶æ ‡å‡†ç­”æ¡ˆè¿›è¡Œè¯„æµ‹ï¼Œè¿™ç§è¯„ä»·æ–¹å¼æ›´åå‘å¯¹æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ï¼Œå­˜åœ¨è¯„ä¼°ç»“æœå’Œæ¨¡å‹çœŸå®èƒ½åŠ›æœ‰â¼€å®šåå·®ã€‚ä¾‹å¦‚ï¼Œè‹±æ–‡æ•°æ®é›†ä¸­ï¼ŒHELM[^1]ä½¿ç”¨16ä¸ªNLPæ•°æ®é›†ï¼ŒMMLU[^2]ç”¨57é¡¹äººç±»è€ƒè¯•ç§‘ç›®æ¥è¯„æµ‹å¤§æ¨¡å‹ã€‚ä¸­æ–‡æ•°æ®é›†ä¸­ï¼ŒGAOKAO[^3]ã€C-Eval[^4]ç­‰ä¹Ÿé‡‡ç”¨äººç±»è¯•é¢˜ï¼Œä»–ä»¬åœ¨è‡ªåŠ¨åŒ–è¯„æµ‹æµç¨‹ä¸­éƒ½åªåŒ…å«æœ‰æ ‡å‡†ç­”æ¡ˆçš„é—®é¢˜ï¼Œæ— æ³•å…¨é¢è¡¡é‡ç”Ÿæˆå¼å¤§æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œç›®å‰ä¹Ÿæœ‰ä¸€äº›å·¥ä½œå…³æ³¨åˆ°äº†æ¨¡å‹çš„å¼€æ”¾å¼é—®ç­”ï¼Œç”±æ–¯å¦ç¦å¤§å­¦æå‡ºçš„çš„AlpacaEval[^5]è¢«å¹¿æ³›è®¤å¯ï¼Œä½†ä»…ç”±è‹±æ–‡é—®é¢˜ç»„æˆï¼Œå†³å®šäº†åªèƒ½è¯„ä¼°æ¨¡å‹åœ¨è‹±æ–‡ä¸Šçš„è¡¨ç°ã€‚åŒ…å«ä¸­æ–‡å¼€æ”¾å¼é—®ç­”çš„SuperCLUE[^6]æ•°æ®é›†æ˜¯é¦–ä¸ªæå‡ºå¼€æ”¾å¼é—®ç­”çš„ä¸­æ–‡æ•°æ®é›†ï¼Œä½†å…¶æ•°æ®é›†é—­æºï¼Œä¸”ä¹Ÿä»…ç”±ä¸­æ–‡é—®é¢˜ç»„æˆã€‚å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰å·²æœ‰çš„å¼€æ”¾å¼é—®é¢˜æ•°æ®é›†éƒ½æ˜¯åœ¨å•ä¸€è¯­è¨€ä¸Šè¿›è¡Œè¯„æµ‹çš„ï¼Œç”¨æ¥è¡¡é‡æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›çš„å¼€æºçš„å¼€æ”¾å¼é—®ç­”æ•°æ®é›†ä»ç„¶ç©ºç¼ºã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæ„å»ºä¸€ä¸ªå¤šè¯­è¨€çš„å¼€æ”¾å¼é—®ç­”æ•°æ®é›†ç”¨ä»¥å…¨é¢è¯„æµ‹å¤§æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›æ˜¯æœ‰å¿…è¦çš„ã€‚æˆ‘ä»¬å°†ä»ä¸­æ–‡å…¥æ‰‹ï¼Œé€æ¸è¿ç§»è‡³å…¶ä»–è¯­è¨€ã€‚

## ä»‹ç»

å¤šè¯­è¨€å¼€æ”¾å¼é—®ç­”æ•°æ®é›†(OMGEvalğŸ˜®: An Open Multilingual Generative Evaluation Benchmark for Foundation Models)ç”±åŒ—äº¬è¯­è¨€å¤§å­¦ã€æ¸…åå¤§å­¦ã€ä¸œåŒ—å¤§å­¦ã€ä¸Šæµ·è´¢ç»å¤§å­¦ç­‰é«˜æ ¡ç»„æˆçš„å›¢é˜Ÿå…±åŒå‘å¸ƒã€‚ä¸»è¦é¡¹ç›®å‚ä¸äººå‘˜æœ‰åˆ˜æ´‹ã€æœ±ç³ã€ä½™å©§æ€ã€å¾èŒã€ç‹èª‰æ°ã€å¸¸é¸¿ç¿”ã€è¢ä½³æ¬£ã€å­”å­˜è‰¯ã€å®‰çºªå…ƒã€æ¨å¤©éºŸã€ç‹ç¡•ã€åˆ˜æ­£çš“ã€é™ˆäº‘ã€æ¨å°”å¼˜ã€åˆ˜æ´‹ã€å­™èŒ‚æ¾ç­‰ã€‚

## æ•°æ®é›†æ„å»ºè¿‡ç¨‹

<div align=center> <img src="./figures/omgeval.png" width="450px"> </div>

### 1. ç¿»è¯‘

ç”¨ChatGPTå°†AlpacaEvalä¸­æ‰€æœ‰çš„å¥å­ç¿»è¯‘æˆä¸­æ–‡ã€‚æˆ‘ä»¬ä½¿ç”¨çš„promptæ˜¯ï¼š

> You are a professional translator. You have tens of years of expertise in translating English to Chinese. You will be given sentence containing a pair of tags <trnslt> and </trnslt>. You need to translate the content between <trnslt> and </trnslt> from English into Chinese. If there is any other languages besides English inside the pair of tags, you will just keep it as it is.The translation must be accurate, fluent, and natural in Chinese. Most importantly, do not lose any information in the translation. Your should enclose your output with <trnslt> and </trnslt> tags. Here are some example inputs and corresponding outputs, you should follow the same format as the output:\n\n Example input :\n\n Translate the following sentence:\n <trnslt>Suppose I have 12 eggs. I drop 2 and eat 5. How many eggs do I have left?</trnslt>\n\n Example output:\n\n <trnslt>å‡è®¾æˆ‘æœ‰ 12 ä¸ªé¸¡è›‹ï¼Œæ‰”äº† 2 ä¸ªï¼Œåƒäº† 5 ä¸ªã€‚æˆ‘è¿˜å‰©ä¸‹å¤šå°‘ä¸ªé¸¡è›‹ï¼Ÿ</trnslt>\n\n

### 2. æœ¬åœ°åŒ–

å¯¹å¤§æ¨¡å‹è¯­è¨€èƒ½åŠ›çš„è¯„æµ‹ä¸ä»…ä»…ä½“ç°åœ¨æé—®å’Œä½œç­”çš„è¯­è¨€æ˜¯ä¸­æ–‡ï¼Œè¿˜æœ‰è¯­è¨€èƒŒåè•´å«çš„æ–‡åŒ–ä¿¡æ¯ã€‚æˆ‘ä»¬å¯¹AlpacaEvalä¸­åŒ…å«æ–‡åŒ–å…ƒç´ çš„å¥å­è¿›è¡Œæœ¬åœ°åŒ–ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºäººç‰©ã€ç”µå½±ä¹¦ç±ç­‰ä½œå“ã€èŠ‚æ—¥ç­‰ã€‚æœ¬åœ°åŒ–çš„ç›®çš„æ˜¯ä½¿è¿™äº›é—®é¢˜éƒ½æ›´åŠ å¥‘åˆä¸­å›½æ–‡åŒ–ã€‚
ä»¥ä¸‹æ˜¯å‡ ä¸ªæœ¬åœ°åŒ–çš„ä¾‹å­ï¼š

```
åŸå§‹å¥å­ï¼šHow did US states get their namesï¼Ÿ
æœ¬åœ°åŒ–åï¼šä¸­å›½å„ä¸ªçœä»½çš„åå­—æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿ
```

```
åŸå§‹å¥å­ï¼šDo you know why turkeys became the official food of thanksgiving?
æœ¬åœ°åŒ–åï¼šä½ çŸ¥é“ä¸ºä»€ä¹ˆç²½å­æ˜¯ç«¯åˆèŠ‚çš„ä¼ ç»Ÿé£Ÿç‰©å—ï¼Ÿ
```

ç»ç»Ÿè®¡ï¼Œæºæ•°æ®é›†ä¸­29.73%ï¼Œå³239ä¸ªå¥å­åšäº†æœ¬åœ°åŒ–çš„ä¿®æ”¹ï¼Œ

### 3. äººå·¥æ ¡éªŒ

å¯¹ç»è¿‡ç¿»è¯‘å’Œæœ¬åœ°åŒ–çš„å¥å­è¿›è¡Œäººå·¥æ ¡éªŒï¼Œæ¯ä¸ªå¥å­ç”±2åæ ‡æ³¨å‘˜ï¼Œ1åå®¡æ ¸å‘˜æ ¡éªŒï¼Œæ ‡æ³¨å‘˜å’Œå®¡æ ¸å‘˜å‡ç”±è¯­è¨€å­¦ä¸“ä¸šçš„ç¡•å£«ç ”ç©¶ç”Ÿæ‹…ä»»ã€‚

## æ•°æ®é›†åˆ†æ

æˆ‘ä»¬æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªåŒ…å«804ä¸ªä¸­æ–‡é—®é¢˜çš„å¼€æ”¾å¼é—®ç­”æ•°æ®é›†ã€‚

æˆ‘ä»¬å°†æ¨¡å‹èƒ½åŠ›åˆ’åˆ†ä¸º9ä¸ªç±»åˆ«ï¼Œåˆ†åˆ«å¦‚ä¸‹

|      | ç±»åˆ«              | å†…å®¹                                       |
| ---- | ----------------- | ------------------------------------------ |
| 1    | ç”Ÿæˆä¸åˆ›ä½œ        | è¥é”€æ–¹æ¡ˆï¼Œå¹¿å‘Šæ–‡æ¡ˆï¼Œé£æ ¼å†™ä½œç­‰             |
| 2    | è¯­è¨€ç†è§£          | è¯­æ³•æ£€æŸ¥ï¼Œé˜…è¯»ç†è§£ï¼Œä¿¡æ¯æŠ½å–ï¼Œä¸Šä¸‹æ–‡å¯¹è¯ç­‰ |
| 3    | çŸ¥è¯†é—®ç­”-ç”Ÿæ´»å¸¸è¯† | ä¸“ä¸šæ€§ä¸å¼ºã€ç”Ÿæ´»åŒ–çš„çŸ¥è¯†é—®ç­”               |
| 4    | çŸ¥è¯†é—®ç­”-ä¸“ä¸šçŸ¥è¯† | ä¸“ä¸šæ€§è¾ƒå¼ºçš„çŸ¥è¯†é—®ç­”                       |
| 5    | é€»è¾‘æ¨ç†          | å¸¸è¯†æ¨ç†ï¼Œç§‘å­¦æ¨ç†ï¼Œäººæ–‡æ¨ç†ç­‰             |
| 6    | ä»£ç èƒ½åŠ›          | ä»£ç ç†è§£ï¼Œä»£ç ç”Ÿæˆï¼Œä»£ç ä¿®æ”¹ç­‰             |
| 7    | æ•°å­¦èƒ½åŠ›          | è®¡ç®—ï¼Œä»£æ•°ï¼Œå‡ ä½•ï¼Œè§£æ–¹ç¨‹ç­‰                 |
| 8    | é—²èŠ              | æ‰“æ‹›å‘¼ï¼Œæ— ç›®çš„çš„å¯¹è¯                                       |
| 9    | æ— å®³åŒ–            | æ¶‰åŠå®—æ•™ã€æ­§è§†ã€è¿æ³•ç­‰åŠ¨ä½œ                   |

æ•°æ®é›†åœ¨è¯„ä¼°èƒ½åŠ›ä¸Šçš„åˆ†å¸ƒå¦‚ä¸‹ï¼š

<div align=center><img src="./figures/data.png" width="450px"> </div>

å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰çš„æ•°æ®é›†ä¸­è¯„ä¼°å„é¡¹èƒ½åŠ›çš„é¢˜ç›®æ•°é‡åˆ†å¸ƒè¿˜ä¸æ˜¯å¤ªå‡è¡¡ï¼Œåç»­æˆ‘ä»¬ä¼šæ–°å¢å¼€æ”¾å¼é¢˜ç›®ä½¿å¾—æ•°æ®å‡è¡¡ã€‚

## è¯„ä¼°æ–¹æ³•

<div align=center><img src="./figures/evaluation.png" width="450px"> </div>

AlpacaEval æ˜¯æ–¯å¦ç¦å¤§å­¦å‘å¸ƒçš„ç”¨äºè‡ªåŠ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„æ’è¡Œæ¦œï¼Œå®ƒåŒ…æ‹¬äº†ä»æµ‹è¯„æ•°æ®é›†ã€æ¨¡å‹å›ç­”ç”Ÿæˆï¼Œåˆ°è‡ªåŠ¨è¯„ä¼°çš„å®Œæ•´è¯„æµ‹æµç¨‹ï¼Œç›®å‰æ¦œå•å·²ç»åŒ…å«äº†æ¥è‡ªå…¨çƒå„ä¸ªæœºæ„çš„å¤šä¸ªä»£è¡¨æ€§æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ’è¡Œæ¦œä¸»è¦è¯„ä¼°å¤§æ¨¡å‹éµä»æŒ‡ä»¤çš„èƒ½åŠ›ä»¥åŠå›ç­”è´¨é‡ï¼Œå…¶ä¸­æ’è¡Œæ¦œæ‰€ä½¿ç”¨çš„æ•°æ®é›†å…±è®¡ 805 æ¡æŒ‡ä»¤ï¼Œé›†æˆäº†æ¥è‡ªäº Self-instructï¼ŒOpen Assistant, Vicuna ç­‰é¡¹ç›®å‘å¸ƒçš„æµ‹è¯„æ•°æ®ã€‚å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ’è¡Œæ¦œçš„å…·ä½“æŒ‡æ ‡è®¡ç®—æ–¹å¼ä¸ºä½¿ç”¨ä¸€ä¸ªå¤§æ¨¡å‹ä½œä¸ºè€ƒå®˜ï¼ˆé€šå¸¸ä¸ºGPT-4ï¼‰ï¼Œè‡ªåŠ¨è¯„ä¼°å½“å‰æ¨¡å‹çš„å›ç­”ä¸é€‰å–çš„åŸºå‡†æ¨¡å‹ï¼ˆé€šå¸¸ä¸ºText-Davinci-003ï¼‰ çš„å›ç­”ï¼Œç»Ÿè®¡å½“å‰æ¨¡å‹çš„èƒœç‡ã€‚

AlpacaEval çš„å®éªŒè¡¨æ˜ï¼Œæ¦œå•æ‰€é‡‡ç”¨çš„ GPT-4 è¯„ä¼°ä¸äººç±»æ ‡æ³¨ç»“æœçš„çš®å°”é€Šç›¸å…³ç³»æ•°è¾¾åˆ° 94%ï¼Œè¯´æ˜è¯¥è¯„ä¼°æ–¹å¼å¯é æ€§è¾ƒé«˜ã€‚åŒæ—¶ï¼Œç ”ç©¶äººå‘˜å¯¹è¯„ä¼°çš„æˆæœ¬ä¹Ÿåšäº†ä¸€å®šçš„åˆ†æï¼Œè¯´æ˜äº†å½“å‰è¯„ä¼°æ–¹å¼å¤§å¹…é™ä½äº†äººå·¥è¯„ä¼°æ‰€èŠ±è´¹çš„ç»æµæˆæœ¬å’Œæ—¶é—´æˆæœ¬ã€‚

å‚è€ƒAlpacaEval çš„è¯„ä¼°æ–¹æ³•ï¼Œæˆ‘ä»¬åŒæ ·é‡‡ç”¨Text-Davinci-003çš„è¾“å‡ºä½œä¸ºåŸºå‡†ï¼Œé‡‡ç”¨GPT-4ä½œä¸ºè¯„ä¼°å™¨ï¼Œä¸ºå¾…è¯„ä¼°æ¨¡å‹å’ŒåŸºå‡†è¾“å‡ºå“ªä¸ªæ›´ä¼˜åšå‡ºåˆ¤æ–­ï¼Œè®¡ç®—èƒœç‡å’Œæ ‡å‡†å·®ã€‚å…·ä½“æ¥çœ‹ï¼Œä¸ºäº†ä¿è¯æ¨¡å‹å¯¹OMGEvalæ•°æ®é›†ä¸­çš„é—®é¢˜çš„è¾“å‡ºéƒ½ä¸ºä¸­æ–‡ï¼Œæˆ‘ä»¬åœ¨promptä¸­ä½¿ç”¨ä¸­æ–‡æé—®ï¼Œæ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹GPT-4è¯„ä¼°æ¨¡å‹è¾“å‡ºçš„promptä¹Ÿåšäº†ç›¸åº”ä¿®æ”¹ï¼Œå¦‚ä¸‹ï¼š

> <|im_start|>system
> ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œä¼šæ ¹æ®æ¨¡å‹çš„å›ç­”è´¨é‡è¿›è¡Œæ’åã€‚
> <|im_end|>
> <|im_start|>user
> æˆ‘æƒ³è®©ä½ åˆ›å»ºä¸€ä¸ªå„ç§å¤§å‹è¯­è¨€æ¨¡å‹çš„æ’è¡Œæ¦œã€‚ä¸ºæ­¤ï¼Œæˆ‘å°†ä¸ºä½ æä¾›ç»™æ¨¡å‹çš„æŒ‡ç¤ºï¼ˆæç¤ºï¼‰ä»¥åŠä¸¤ä¸ªæ¨¡å‹çš„å›åº”ã€‚è¯·æ ¹æ®äººç±»åå¥½å¯¹æ¨¡å‹è¿›è¡Œæ’åã€‚æ‰€æœ‰çš„è¾“å…¥å’Œè¾“å‡ºéƒ½åº”è¯¥æ˜¯Pythonå­—å…¸ã€‚
>
> è¿™é‡Œæ˜¯æŒ‡ä»¤:
> {
> "instruction": """{instruction}""",
> }
>
> è¿™é‡Œæ˜¯ä¸¤ä¸ªæ¨¡å‹çš„è¾“å‡º:
> [
> {
> "model": "model_1",
> "answer": """{output_1}"""
> },
> {
> "model": "model_2",
> "answer": """{output_2}"""
> }
> ]
>
> ç°åœ¨è¯·æ ¹æ®å®ƒä»¬çš„å›ç­”è´¨é‡å¯¹æ¨¡å‹è¿›è¡Œæ’åï¼Œä½¿å¾—æ’åç¬¬ä¸€çš„æ¨¡å‹å…·æœ‰æœ€ä½³è¾“å‡ºã€‚ä½ éœ€è¦è¿”å›ä¸€ä¸ªåŒ…å«æ¨¡å‹åç§°å’Œæ’åçš„åˆ—è¡¨ï¼Œå³ç”Ÿæˆä»¥ä¸‹è¾“å‡ºï¼š
> [
> {'model': <model-name>, 'rank': <model-rank>},
> {'model': <model-name>, 'rank': <model-rank>}
> ]
>
> ä½ çš„å›å¤å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„Pythonå­—å…¸ï¼Œä¸åº”åŒ…å«å…¶ä»–ä»»ä½•å†…å®¹ï¼Œå› ä¸ºæˆ‘ä»¬å°†ç›´æ¥åœ¨Pythonä¸­æ‰§è¡Œå®ƒã€‚è¯·æä¾›å¤§å¤šæ•°äººä¼šç»™å‡ºçš„æ’åã€‚
> <|im_end|>

## è¯„ä¼°æ¦œå•

æ ¹æ®ä¸Šè¿°è¯„ä¼°æ–¹æ³•ï¼Œé‡‡ç”¨Text-Davinci-003çš„è¾“å‡ºä½œä¸ºåŸºå‡†ï¼Œé‡‡ç”¨GPT-4ä½œä¸ºè¯„ä¼°å™¨ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹æ¦œå•ï¼š

|                  | win_rate | standard_error |
| :--------------- | :------- | :------------: |
| ChatGPT          | 91.52    |      0.98      |
| text_davinci_003 | 50.00    |      0.00      |

æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹239ä¸ªåšäº†æœ¬åœ°åŒ–çš„é—®é¢˜åšäº†å•ç‹¬çš„è¯„æµ‹ï¼Œç›®çš„æ˜¯è¯„æµ‹ä¸åŒè¯­è¨€çš„å¤§æ¨¡å‹åœ¨æ¶‰åŠåˆ°ä¸­æ–‡æ–‡åŒ–ä¸Šçš„è¡¨ç°ï¼Œæ¦œå•å¦‚ä¸‹ï¼š

|                  | win_rate | standard_error |
| :---------------: | :-------: | :------------: |
| ChatGPT         | 87.45    |     2.15       |
| text_davinci_003 | 50.00    |      0.00      |

å¯ä»¥çœ‹åˆ°ï¼ŒChatGPTåœ¨æœ¬åœ°åŒ–çš„é—®é¢˜é›†ä¸Šå¾—åˆ†ä½äºåœ¨é—®é¢˜å…¨é›†ä¸Šçš„å¾—åˆ†ã€‚

æ›´å¤šæ¨¡å‹ä»åœ¨è¯„æµ‹ä¸­ğŸš§ï¼Œæ•¬è¯·æœŸå¾…ã€‚

## To-do List

- [ ] æ›´æ–°æ¦œå•ï¼Œæ·»åŠ GPT-4ã€vicuna-7Bç­‰æ¨¡å‹

- [ ] æ‰©å……æ•°æ®é›†ï¼Œä½¿å¾—æ•°æ®é›†åœ¨è¯„ä¼°èƒ½åŠ›åˆ†ç±»ä¸Šåˆ†å¸ƒå‡è¡¡
- [ ] æ‰©å±•åˆ°å¤šè¯­è¨€

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬é¡¹ç›®çš„å†…å®¹ï¼Œæˆ–è€…è®¤ä¸ºæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æœ¬é¡¹ç›®ã€‚

```Plaintext
@misc{OMGEval,
  author={Yang Liu  and Lin Zhu and Jingsi Yu and Meng Xu and Yujie Wang and Hongxiang Chang and Jiaxin Yuan and Cunliang Kong and Jiyuan An and Tianlin Yang and Shuo Wang and Zhenghao Liu and Yun Chen and Erhong Yang and Yang Liu and Maosong Sun},
  title={OMGEvalğŸ˜®: An Open Multilingual Generative Evaluation Benchmark for Foundation Models},
  year={2023},
  publisher={GitHub},
  journal={GitHub repository},
  howpublished={\url{https://github.com/blcuicall/OMGEval}},
}
```

**å‚è€ƒæ–‡çŒ®**

[^1]: Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher RÃ©, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, Yuta Koreeda. 2022. Holistic Evaluation of Language Models. arXiv preprint arXiv:2211.09110.

[^2]: Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt. 2020. Measuring Massive Multitask Language Understanding. arXiv preprint arXiv:2009.03300.

[^3]: Xiaotian Zhang, Chunyang Li, Yi Zong, Zhengyu Ying, Liang He, Xipeng Qiu. 2023. Evaluating the Performance of Large Language Models on GAOKAO Benchmark. arXiv preprint arXiv:2305.12474.

[^4]: Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, Junxian He. 2023. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. arXiv preprint arXiv:2305.08322.

[^5]: Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, Tatsunori B. Hashimoto. 2023. AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback. arXiv preprint arXiv:2305.14387.

[^6]: Liang Xu, Anqi Li, Lei Zhu, Hang Xue, Changtai Zhu, Kangkang Zhao, Haonan He, Xuanwei Zhang, Qiyue Kang, Zhenzhong Lan. 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. arXiv preprint arXiv:2307.15020.

